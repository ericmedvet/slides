class: middle, center

# Virtual memory

---

## Goals

Goal of cache: memory with fast access and large size

Unsolved issues:
1. memory used by many programs at the same time
2. physical memory being smaller than addressable memory

---

### Memory sharing

Suppose program $A$ and program $B$ are being executed **concurrently**: .note[we'll see, briefly, how]

**Question**:
- how to prevent $A$ from accessing an $x$ address that "belongs" to $B$?


Trivial, but *wrong*, solution: make $A$ access addresses from $x\_{A,i}$ to $x\_{A,f}$ and $B$ access from $x\_{B,i}$ to $x\_{B,f}$, with $[x\_{A,i},x\_{A,f}]$ and $[x\_{B,i},x\_{B,f}]$ being disjoint...
- works only for $A$ and $B$, what about $C$, $D$, ...
- works only if $[x\_{A,i},x\_{A,f}]$ is free (same for $B$)
- require knowing $[x\_{A,i},x\_{A,f}]$ at compile time

---

### Addressable memory

In ancient times, RAMs were small, much smaller than the addressable space (i.e., $2^{n\_m}$)

Today, RAMs are much bigger, but still often smaller than addressable space:
- $n\_m=32$ means 4 GB: not all computers have 4 GB RAM
- $n\_m=64$ means 18 exabytes... .note[actually, depends on the architecture: usually "much" lower]

**Questions**:
- how to allow programs to use a memory of $2^{n\_m}$ bytes having a physical memory that is smaller?
- (further) how to make all running programs "see" a memory of size $2^{n\_m}$?

---

## Idea (sketch of)

At any time, the memory content is only partially in the physical memory (RAM); the remaining part is on the disk

When a program wants to access a given address, it may be on the physical memory:
- if yes, nice
- if not, find it on the disk, bring it to the physical memory, and use it

Solves the issue of size, not that of concurrent access to memory

---

## Idea (finer sketch of)

Memory is organized in **pages**:
- each page has a **page number**
- within page, bytes has an address (**page offset**) starting at 0
- a physical memory location is composed of a page number *and* a page offset

Each program is given a page and accesses memory specifying the page offset

Solves the issues of concurrent access, not that of size
- $A$ cannot access the page of $B$
- $A$ is compiled specifying just the page offset, the page number at runtime is assigned by *someone*

---

## Idea (together)

- memory is organized in pages
- programs are given **many** pages, not just one
  - from program POV, the first has always number 0
- at any time a page may be in the physical memory or on the disk
  - programs do not need to know if a page is on memory or on disk

Solves all problems:
- there can be *as many pages as we want*, actually a number of pages that is *like* $2^{n\_m}$ bytes for each program
- no undesired interference among programs .note[there can be regulated sharing of page, though]

This way, what is seen by programs is a larger, private memory that is not the physical memory: $\rightarrow$ **virtual memory**

---

## Virtual memory and addresses

From program point of view, a memory address is given by $\langle$page number, page offset$\rangle$
- each program has pages starting from number 0

But physically, bytes are either in RAM or on disk
- in general, not starting "at 0"

$\Rightarrow$ addresses has to be **translated**

---

## Virtual memory and caches

There are similarities:
- both motivated by "have your cake and eat it too"
- both exploit a memory hierarchy (i.e., two memories)
- both are organized in chunks
- both require an address translation

| | Cache | Virtual memory |
| - | - | - |
| Goal | fast as SRAM, large as DRAM | private as split for programs, large as entire for each program |
| Two memories | SRAM and DRAM | DRAM and disk |
| Chunks | block | page |
| Address translation | $x$ to $y$ (or $Y$) | we'll see |

.note[Names are different for historical reasons]

---

## Address translation

In cache:
- $x$ is the physical address in the (main) memory .note[in general, the lower level memory]
- $y$ is the physical block address in the cache

In virtual memory:
- $x_v$ is the **virtual address**
  - generated by the program
- $x_p$ is the **physical address**


---

### Address parts

Assume:
- a virtual memory addressable with $n\_v=32$ bits
- a page size of $s\_p=16$ KB, i.e., $n\_p=\log\_2 (16 \cdot 1024) = 4 + 10 = 14$

A virtual address is composed of:
- the page number, ranging from $0$ to $s\_n=\frac{2^{32}}{2^{14}}$, i.e., $n\_n = n\_v - n\_p = 18$

In general, the virtual memory can be larger than the physical memory (*illusion* of large memory):
- $n\_v > n\_m$, e.g., $n\_v=48$ and $n\_m = 40$

---

## Finding a page

Assume a program wants to access $x_v$: what happens?

In brief and conceptually:
1. get page number $p\_v=x\_{v [0, n\_n[}$ from $x\_v$
2. if page $p$ is in physical memory
  - translate $x\_v$ to $x\_p$
  - access it
3. otherwise (**page fault**)
  - find it on disk .note[where?]
  - move it in memory .note[where? remove what?]
  - translate $x\_v$ to $x\_p$
  - access it

Looks very like the case of cache, but...

---

## Cost of miss vs. fault

| Type | Access time [ns] | Cost [$/GB] |
| - | - | - |
| SRAM | 0.5–2.5 | 500–1000 |
| DRAM | 50–70 | 10–20 |
| Flash | 5000–50000 | 0.75–1.00 |
| Magnetic disk | 5000000–20000000 | 0.05–0.10 |

Cache:
- hit (SRAM): 1 cycle
- miss (DRAM): $\approx \frac{50}{0.5}=100$ cycles, $100 \times$ longer

Virtual memory:
- hit (DRAM): $t \approx 50$
- fault (disk): $t \approx 5 \cdot 10^3$, $100000 \times$ longer
  - much uglier if said in cycles: millions of!

---

## Cost of page fault

Since the cost of page faults is very high, greater care is put in reducing page fault probability:
- full associativity
  - with smarter replacement strategies employed by OS .note[operating system]
- much larger chunk size
  - exploits high bandwidth, despite big latency, of disks
- write back
  - write through would be very unpractical ($100000 \times$ longer)

---

## Page table

**Every program** has a **page table** consisting of $2^{n\_n}$ entries

Each entry contains:
- one validity bit
- a physical page number $p\_p$ of $n\_m-n\_p$ bits .note[the $n\_p$ bits are the page offset]

The translation from $x\_v$ to $x\_p$ is a look-up in the page table:
1. take $p\_v=x\_{v [0, n\_n[}$
2. look at $p\_v$-th entry in the page table
3. if the validity bit is set (**hit**), $x\_p = p\_p x\_{v [n\_n, n\_v[}$
4. otherwise (**miss**) ...

.question[No tag: why?]

---

## Program state

For a program, the page table is in memory
- hardware is optimized for keeping the address of the page table (that is accessed frequently) in a specific registry

**State** of a program (also called **process**):
- program counter
- registers
- page table (address)

State can be stored (in memory) and restored back:
- **active** process if contents above are in place
- **inactive** process otherwise

---

## Page location on fault

The page table does not contain the physical address of the faulted page on the disk

The OS takes care of reserving a disk portion for *all* the pages of each project: **swap space** .note[actually, things can be more complex]
- usually pages for a program are contiguous on swap space
- $p\_v$ can be easily translated to a position on the swap disk for a given program

**OS takes care of page faults!**
- they are long enough to make convinient the management by sw instead of hw

.note[first request for a page does not need to go on disk for reading]

---

## Replacement policy

Because of full associativity, any page table entry can be replaced

Since replacement is managed by OS, replacement policy may be complex (e.g., LRU may be preferable over random)

However, real LRU is still too costly, since require updating usage info at each access, not only upon faults

$\Rightarrow$ *approximated* LRU with usage bit

---

## Usage/reference bit

Each entry in the page table contains:
- one validity bit
- one **usage** or reference bit
- a physical page number $p\_p$

At every hit, the usage bit is set

Every while, **all** usage bits are unset

.note[for bits, "set" is "set to .memory[1]", "unset" is "set to .memory[0]"]

.question[How to estimate the effectiveness of dirty bit with respect to actual LRU?]

---

## Size of page table

The page table may be **very large**!

E.g., for $n\_v=48$, $n\_p=14$, $n\_m=40$, there are $2^{n\_n}$ entries, each consisting of $1+1+n\_m-n\_p=28$ bits, with $n\_n=n\_v-n\_p=48-14=34$  
$\Rightarrow$ $28 \cdot 2^{34} \approx 60$ GB!!! one per each process!!!

Unfeasible to take them in memory!

Optimizations:
- use smaller tables (process address a smaller virtual memory)
- use dynamic tables (initially small, grown on need)
  - possibly in two directions for heap/stack growing requests
- hash the the virtual page numbers (*inverted page table*)
- page the page table!
- ...

---

## Writes

**Write back** policy with optimization: for avoding writing back when unneeded (because the page has not be written)

Each entry in the page table contains:
- one validity bit
- one usage bit
- one **dirty** bit
- a physical page number $p\_p$

Upon read/creation, the dirty bit is unset

Upon writes on the page, the dirty bit is set
